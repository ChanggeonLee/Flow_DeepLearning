{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichang-geon/.pyenv/versions/2.7.14/envs/flow/lib/python2.7/site-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/ichang-geon/.pyenv/versions/2.7.14/envs/flow/lib/python2.7/site-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/Users/ichang-geon/.pyenv/versions/2.7.14/envs/flow/lib/python2.7/site-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob as glb\n",
    "from tqdm import *\n",
    "import h5py\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "min_queue_examples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flow(filename, shape):\n",
    "  stream_flow = h5py.File(filename, 'r')\n",
    "  flow_state_vel = np.array(stream_flow['Velocity_0'][:])\n",
    "  flow_state_vel = flow_state_vel.reshape([shape[0], shape[1]+128, 3])[0:shape[0],0:shape[1],0:2]\n",
    "  stream_flow.close()\n",
    "  return flow_state_vel\n",
    "\n",
    "def load_boundary(filename, shape):\n",
    "  stream_boundary = h5py.File(filename, 'r')\n",
    "  boundary_cond = np.array(stream_boundary['Gamma'][:])\n",
    "  boundary_cond = boundary_cond.reshape([shape[0], shape[1]+128, 1])[0:shape[0],0:shape[1],:]\n",
    "  stream_boundary.close()\n",
    "  return boundary_cond\n",
    "\n",
    "def read_data(filename_queue, shape):\n",
    "  reader = tf.TFRecordReader()\n",
    "  key, serialized_example = reader.read(filename_queue)\n",
    "  features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "      'boundary':tf.FixedLenFeature([],tf.string),\n",
    "      'sflow':tf.FixedLenFeature([],tf.string),\n",
    "      'vmax':tf.FixedLenFeature([],tf.int64),\n",
    "    }) \n",
    "  boundary = tf.decode_raw(features['boundary'], tf.uint8)\n",
    "  sflow = tf.decode_raw(features['sflow'], tf.float32)\n",
    "  vmax = tf.cast(features['vmax'], tf.int32)\n",
    "\n",
    "  boundary = tf.reshape(boundary, [shape[0], shape[1], 1])\n",
    "  sflow = tf.reshape(sflow, [shape[0], shape[1], 2])\n",
    "  boundary = tf.to_float(boundary)\n",
    "  sflow = tf.to_float(sflow)\n",
    "\n",
    "  return boundary, sflow, vmax\n",
    "\n",
    "def _generate_image_label_batch(boundary, sflow, vmax, batch_size, shuffle=True):\n",
    "  num_preprocess_threads = 1\n",
    "  #Create a queue that shuffles the examples, and then\n",
    "  #read 'batch_size' images + labels from the example queue.\n",
    "  boundarys, sflows, vmax = tf.train.shuffle_batch(\n",
    "    [boundary, sflow, vmax],\n",
    "    batch_size=batch_size,\n",
    "    num_threads=num_preprocess_threads,\n",
    "    capacity=min_queue_examples + 3 * batch_size,\n",
    "    min_after_dequeue=min_queue_examples)\n",
    "  return boundarys, sflows, vmax\n",
    "\n",
    "def flow_inputs(batch_size):\n",
    "  shape = (128,256)\n",
    "\n",
    "  tfrecord_filename = glb('../data/*.tfrecords') \n",
    "  \n",
    "  filename_queue = tf.train.string_input_producer(tfrecord_filename) \n",
    "\n",
    "  boundary, sflow,vmax = read_data(filename_queue, shape)\n",
    "\n",
    "  boundarys, sflows, vmax = _generate_image_label_batch(boundary, sflow,vmax, batch_size)\n",
    "\n",
    "  return boundarys, sflows, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ToFloat_2:0\", shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_batch = 8\n",
    "learning_rate = 0.0001\n",
    "keep_prob = 0.7\n",
    "n_hidden = 128\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32 , [None,128,256,1], name=\"X\")\n",
    "\n",
    "boundary, sflow, vmax = flow_inputs(n_batch)\n",
    "X = boundary\n",
    "\n",
    "v = tf.placeholder(tf.float32 ,vmax.shape, name=\"v\")\n",
    "v = tf.to_float(vmax)\n",
    "\n",
    "print(v)\n",
    "\n",
    "#Conv1\n",
    "W1 = tf.Variable(tf.random_normal([16, 16, 1, 128], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 8, 16, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cov2\n",
    "W2 = tf.Variable(tf.random_normal([4,4,128,512], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 4, 4, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_flat = tf.reshape(L2,[-1,4*4*512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W\", shape=[512 * 4 * 4, 1024],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_2/mul:0\", shape=(8, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b3 = tf.Variable(tf.random_normal([1024]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2_flat, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "print(L3)\n",
    "# vmax를 state로 주고 input으로 L3를 RNN에 넣은다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN layer\n",
    "\n",
    "WR = tf.Variable(tf.random_normal([n_hidden , 1024], stddev=0.01))\n",
    "BR = tf.Variable(tf.random_normal([1024]))\n",
    "\n",
    "L3 = tf.reshape(L3 , [n_batch,1024,1])\n",
    "state = v\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_hidden,reuse=tf.AUTO_REUSE)\n",
    "model, states = tf.nn.dynamic_rnn(cell=cell, inputs=L3, dtype=tf.float32, time_major=False)\n",
    "model = tf.layers.dense(model,units=1,activation=None)\n",
    "model = tf.nn.relu(model)\n",
    "L3 = tf.reshape(model,[n_batch,1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L3 = tf.divide(L3,y)\n",
    "S1, S2 = tf.split(L3, [512, 512], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1= tf.reshape(S1,[n_batch,1,1,512])\n",
    "S2= tf.reshape(S2,[n_batch,1,1,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconv1\n",
    "W4_1 = tf.Variable(tf.random_normal([8,8,512,512], stddev=0.01))\n",
    "L4_1 = tf.nn.conv2d_transpose(S1,W4_1,output_shape=[n_batch,8,8,512],strides=[1,8, 8, 1], padding='SAME')\n",
    "L4_1 = tf.nn.relu(L4_1)\n",
    "L4_1 = tf.nn.dropout(L4_1, keep_prob)\n",
    "\n",
    "W4_2 = tf.Variable(tf.random_normal([8,8,512,512], stddev=0.01))\n",
    "L4_2 = tf.nn.conv2d_transpose(S2,W4_2,output_shape=[n_batch,8,8,512],strides=[1,8, 8, 1], padding='SAME')\n",
    "L4_2 = tf.nn.relu(L4_2)\n",
    "L4_2 = tf.nn.dropout(L4_2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deconv2\n",
    "W5_1 = tf.Variable(tf.random_normal([4,8,256,512], stddev=0.01))\n",
    "L5_1 = tf.nn.conv2d_transpose(L4_1,W5_1,output_shape=[n_batch,32,64,256],strides=[1, 4, 8, 1], padding='SAME')\n",
    "L5_1 = tf.nn.relu(L5_1)\n",
    "L5_1 = tf.nn.dropout(L5_1, keep_prob)\n",
    "\n",
    "W5_2 = tf.Variable(tf.random_normal([4,8,256,512], stddev=0.01))\n",
    "L5_2 = tf.nn.conv2d_transpose(L4_2,W5_2,output_shape=[n_batch,32,64,256],strides=[1,4, 8, 1], padding='SAME')\n",
    "L5_2 = tf.nn.relu(L5_2)\n",
    "L5_2 = tf.nn.dropout(L5_2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconv3\n",
    "W6_1 = tf.Variable(tf.random_normal([2,2,32,256], stddev=0.01))\n",
    "L6_1 = tf.nn.conv2d_transpose(L5_1,W6_1,output_shape=[n_batch,64,128,32],strides=[1,2, 2, 1], padding='SAME')\n",
    "L6_1 = tf.nn.relu(L6_1)\n",
    "L6_1 = tf.nn.dropout(L6_1, keep_prob)\n",
    "\n",
    "W6_2 = tf.Variable(tf.random_normal([2,2,32,256], stddev=0.01))\n",
    "L6_2 = tf.nn.conv2d_transpose(L5_2,W6_2,output_shape=[n_batch,64,128,32],strides=[1,2, 2, 1], padding='SAME')\n",
    "L6_2 = tf.nn.relu(L6_2)\n",
    "L6_2 = tf.nn.dropout(L6_2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconv4\n",
    "W7_1 = tf.Variable(tf.random_normal([2,2,1,32], stddev=0.01))\n",
    "L7_1 = tf.nn.conv2d_transpose(L6_1,W7_1,output_shape=[n_batch,128,256,1],strides=[1,2,2, 1], padding='SAME')\n",
    "L7_1 = tf.nn.dropout(L7_1, keep_prob)\n",
    "\n",
    "W7_2 = tf.Variable(tf.random_normal([2,2,1,32], stddev=0.01))\n",
    "L7_2 = tf.nn.conv2d_transpose(L6_2,W7_2,output_shape=[n_batch,128,256,1],strides=[1,2, 2, 1], padding='SAME')\n",
    "L7_2 = tf.nn.dropout(L7_2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sflow_p = tf.stack([L7_1 , L7_2] , axis=3)\n",
    "sflow_p = tf.reshape(sflow_p , [n_batch,128,256,2])\n",
    "# loss = tf.reduce_mean(tf.square(sflow_p - sflow))\n",
    "loss = tf.nn.l2_loss(sflow_p - sflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loss \n",
    "total_loss = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "ckpt = tf.train.get_checkpoint_state('./model_save')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany, started daemon 123145444679680)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 123145448886272)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = sess.run([v],feed_dict={})\n",
    "# print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'Avg. cost =', '610.915710')\n",
      "('Epoch:', '0002', 'Avg. cost =', '458.887634')\n",
      "('Epoch:', '0003', 'Avg. cost =', '628.047363')\n",
      "('Epoch:', '0004', 'Avg. cost =', '858.528625')\n",
      "('Epoch:', '0005', 'Avg. cost =', '616.375061')\n",
      "('Epoch:', '0006', 'Avg. cost =', '506.004272')\n",
      "('Epoch:', '0007', 'Avg. cost =', '858.511047')\n",
      "('Epoch:', '0008', 'Avg. cost =', '914.012451')\n",
      "('Epoch:', '0009', 'Avg. cost =', '842.890503')\n",
      "('Epoch:', '0010', 'Avg. cost =', '461.316803')\n",
      "('Epoch:', '0011', 'Avg. cost =', '571.886230')\n",
      "('Epoch:', '0012', 'Avg. cost =', '146.558914')\n",
      "('Epoch:', '0013', 'Avg. cost =', '887.718750')\n",
      "('Epoch:', '0014', 'Avg. cost =', '499.093231')\n",
      "('Epoch:', '0015', 'Avg. cost =', '446.360657')\n",
      "('Epoch:', '0016', 'Avg. cost =', '661.914673')\n",
      "('Epoch:', '0017', 'Avg. cost =', '600.225220')\n",
      "('Epoch:', '0018', 'Avg. cost =', '653.355103')\n",
      "('Epoch:', '0019', 'Avg. cost =', '703.898560')\n",
      "('Epoch:', '0020', 'Avg. cost =', '438.500793')\n",
      "('Epoch:', '0021', 'Avg. cost =', '600.845093')\n",
      "('Epoch:', '0022', 'Avg. cost =', '482.413635')\n",
      "('Epoch:', '0023', 'Avg. cost =', '444.067932')\n",
      "('Epoch:', '0024', 'Avg. cost =', '532.002075')\n",
      "('Epoch:', '0025', 'Avg. cost =', '274.637421')\n",
      "('Epoch:', '0026', 'Avg. cost =', '411.123932')\n",
      "('Epoch:', '0027', 'Avg. cost =', '471.755493')\n",
      "('Epoch:', '0028', 'Avg. cost =', '575.541687')\n",
      "('Epoch:', '0029', 'Avg. cost =', '282.480499')\n",
      "('Epoch:', '0030', 'Avg. cost =', '640.225281')\n",
      "('Epoch:', '0031', 'Avg. cost =', '1001.807617')\n",
      "('Epoch:', '0032', 'Avg. cost =', '613.666992')\n",
      "('Epoch:', '0033', 'Avg. cost =', '491.240723')\n",
      "('Epoch:', '0034', 'Avg. cost =', '823.765503')\n",
      "('Epoch:', '0035', 'Avg. cost =', '498.328308')\n",
      "('Epoch:', '0036', 'Avg. cost =', '690.143921')\n",
      "('Epoch:', '0037', 'Avg. cost =', '953.232544')\n",
      "('Epoch:', '0038', 'Avg. cost =', '473.906647')\n",
      "('Epoch:', '0039', 'Avg. cost =', '806.454346')\n",
      "('Epoch:', '0040', 'Avg. cost =', '552.960754')\n",
      "('Epoch:', '0041', 'Avg. cost =', '344.797699')\n",
      "('Epoch:', '0042', 'Avg. cost =', '402.850769')\n",
      "('Epoch:', '0043', 'Avg. cost =', '643.807068')\n",
      "('Epoch:', '0044', 'Avg. cost =', '711.764038')\n",
      "('Epoch:', '0045', 'Avg. cost =', '435.884277')\n",
      "('Epoch:', '0046', 'Avg. cost =', '463.288483')\n",
      "('Epoch:', '0047', 'Avg. cost =', '383.454590')\n",
      "('Epoch:', '0048', 'Avg. cost =', '505.388275')\n",
      "('Epoch:', '0049', 'Avg. cost =', '574.787170')\n",
      "('Epoch:', '0050', 'Avg. cost =', '509.910828')\n",
      "('Epoch:', '0051', 'Avg. cost =', '459.949860')\n",
      "('Epoch:', '0052', 'Avg. cost =', '341.458069')\n",
      "('Epoch:', '0053', 'Avg. cost =', '347.886536')\n",
      "('Epoch:', '0054', 'Avg. cost =', '348.382202')\n",
      "('Epoch:', '0055', 'Avg. cost =', '775.919067')\n",
      "('Epoch:', '0056', 'Avg. cost =', '448.011536')\n",
      "('Epoch:', '0057', 'Avg. cost =', '581.512878')\n",
      "('Epoch:', '0058', 'Avg. cost =', '382.988647')\n",
      "('Epoch:', '0059', 'Avg. cost =', '446.362183')\n",
      "('Epoch:', '0060', 'Avg. cost =', '779.281494')\n",
      "('Epoch:', '0061', 'Avg. cost =', '826.463013')\n",
      "('Epoch:', '0062', 'Avg. cost =', '380.329803')\n",
      "('Epoch:', '0063', 'Avg. cost =', '716.542236')\n",
      "('Epoch:', '0064', 'Avg. cost =', '326.214813')\n",
      "('Epoch:', '0065', 'Avg. cost =', '815.976440')\n",
      "('Epoch:', '0066', 'Avg. cost =', '647.416077')\n",
      "('Epoch:', '0067', 'Avg. cost =', '599.551147')\n",
      "('Epoch:', '0068', 'Avg. cost =', '735.290283')\n",
      "('Epoch:', '0069', 'Avg. cost =', '561.501892')\n",
      "('Epoch:', '0070', 'Avg. cost =', '585.237305')\n",
      "('Epoch:', '0071', 'Avg. cost =', '418.010742')\n",
      "('Epoch:', '0072', 'Avg. cost =', '638.226868')\n",
      "('Epoch:', '0073', 'Avg. cost =', '884.468933')\n",
      "('Epoch:', '0074', 'Avg. cost =', '774.617004')\n",
      "('Epoch:', '0075', 'Avg. cost =', '426.963348')\n",
      "('Epoch:', '0076', 'Avg. cost =', '588.007935')\n",
      "('Epoch:', '0077', 'Avg. cost =', '433.788269')\n",
      "('Epoch:', '0078', 'Avg. cost =', '396.263824')\n",
      "('Epoch:', '0079', 'Avg. cost =', '361.434052')\n",
      "('Epoch:', '0080', 'Avg. cost =', '852.221375')\n",
      "('Epoch:', '0081', 'Avg. cost =', '438.560791')\n",
      "('Epoch:', '0082', 'Avg. cost =', '630.445679')\n",
      "('Epoch:', '0083', 'Avg. cost =', '570.528320')\n",
      "('Epoch:', '0084', 'Avg. cost =', '616.488281')\n",
      "('Epoch:', '0085', 'Avg. cost =', '683.882080')\n",
      "('Epoch:', '0086', 'Avg. cost =', '514.188293')\n",
      "('Epoch:', '0087', 'Avg. cost =', '661.967651')\n",
      "('Epoch:', '0088', 'Avg. cost =', '842.987854')\n",
      "('Epoch:', '0089', 'Avg. cost =', '539.681030')\n",
      "('Epoch:', '0090', 'Avg. cost =', '416.544739')\n",
      "('Epoch:', '0091', 'Avg. cost =', '709.694946')\n",
      "('Epoch:', '0092', 'Avg. cost =', '434.563202')\n",
      "('Epoch:', '0093', 'Avg. cost =', '510.215881')\n",
      "('Epoch:', '0094', 'Avg. cost =', '590.744751')\n",
      "('Epoch:', '0095', 'Avg. cost =', '712.277100')\n",
      "('Epoch:', '0096', 'Avg. cost =', '878.163696')\n",
      "('Epoch:', '0097', 'Avg. cost =', '580.129517')\n",
      "('Epoch:', '0098', 'Avg. cost =', '1041.595825')\n",
      "('Epoch:', '0099', 'Avg. cost =', '875.658142')\n",
      "('Epoch:', '0100', 'Avg. cost =', '717.205017')\n",
      "('Epoch:', '0101', 'Avg. cost =', '420.434753')\n",
      "('Epoch:', '0102', 'Avg. cost =', '458.151062')\n",
      "('Epoch:', '0103', 'Avg. cost =', '466.647919')\n",
      "('Epoch:', '0104', 'Avg. cost =', '660.156982')\n",
      "('Epoch:', '0105', 'Avg. cost =', '673.910767')\n",
      "('Epoch:', '0106', 'Avg. cost =', '419.687286')\n",
      "('Epoch:', '0107', 'Avg. cost =', '714.705566')\n",
      "('Epoch:', '0108', 'Avg. cost =', '689.012390')\n",
      "('Epoch:', '0109', 'Avg. cost =', '683.823853')\n",
      "('Epoch:', '0110', 'Avg. cost =', '566.892822')\n",
      "('Epoch:', '0111', 'Avg. cost =', '396.169006')\n",
      "('Epoch:', '0112', 'Avg. cost =', '634.701416')\n",
      "('Epoch:', '0113', 'Avg. cost =', '522.843140')\n",
      "('Epoch:', '0114', 'Avg. cost =', '205.715073')\n",
      "('Epoch:', '0115', 'Avg. cost =', '648.291870')\n",
      "('Epoch:', '0116', 'Avg. cost =', '518.897827')\n",
      "('Epoch:', '0117', 'Avg. cost =', '587.170532')\n",
      "('Epoch:', '0118', 'Avg. cost =', '216.501511')\n",
      "('Epoch:', '0119', 'Avg. cost =', '418.197113')\n",
      "('Epoch:', '0120', 'Avg. cost =', '305.188141')\n",
      "('Epoch:', '0121', 'Avg. cost =', '177.816025')\n",
      "('Epoch:', '0122', 'Avg. cost =', '539.324036')\n",
      "('Epoch:', '0123', 'Avg. cost =', '860.639832')\n",
      "('Epoch:', '0124', 'Avg. cost =', '403.603027')\n",
      "('Epoch:', '0125', 'Avg. cost =', '314.392456')\n",
      "('Epoch:', '0126', 'Avg. cost =', '557.190674')\n",
      "('Epoch:', '0127', 'Avg. cost =', '826.921753')\n",
      "('Epoch:', '0128', 'Avg. cost =', '552.715454')\n",
      "('Epoch:', '0129', 'Avg. cost =', '457.051819')\n",
      "('Epoch:', '0130', 'Avg. cost =', '708.331726')\n",
      "('Epoch:', '0131', 'Avg. cost =', '299.404846')\n",
      "('Epoch:', '0132', 'Avg. cost =', '752.820068')\n",
      "('Epoch:', '0133', 'Avg. cost =', '533.842590')\n",
      "('Epoch:', '0134', 'Avg. cost =', '757.875061')\n",
      "('Epoch:', '0135', 'Avg. cost =', '756.796875')\n",
      "('Epoch:', '0136', 'Avg. cost =', '981.819824')\n",
      "('Epoch:', '0137', 'Avg. cost =', '702.270020')\n",
      "('Epoch:', '0138', 'Avg. cost =', '307.589661')\n",
      "('Epoch:', '0139', 'Avg. cost =', '627.125854')\n",
      "('Epoch:', '0140', 'Avg. cost =', '290.498474')\n",
      "('Epoch:', '0141', 'Avg. cost =', '422.353760')\n",
      "('Epoch:', '0142', 'Avg. cost =', '398.628479')\n",
      "('Epoch:', '0143', 'Avg. cost =', '587.707275')\n",
      "('Epoch:', '0144', 'Avg. cost =', '681.017151')\n",
      "('Epoch:', '0145', 'Avg. cost =', '475.699005')\n",
      "('Epoch:', '0146', 'Avg. cost =', '628.599121')\n",
      "('Epoch:', '0147', 'Avg. cost =', '463.688263')\n",
      "('Epoch:', '0148', 'Avg. cost =', '742.983398')\n",
      "('Epoch:', '0149', 'Avg. cost =', '738.592529')\n",
      "('Epoch:', '0150', 'Avg. cost =', '359.285950')\n",
      "('Epoch:', '0151', 'Avg. cost =', '735.496216')\n",
      "('Epoch:', '0152', 'Avg. cost =', '453.266602')\n",
      "('Epoch:', '0153', 'Avg. cost =', '832.962646')\n",
      "('Epoch:', '0154', 'Avg. cost =', '423.976593')\n",
      "('Epoch:', '0155', 'Avg. cost =', '785.185974')\n",
      "('Epoch:', '0156', 'Avg. cost =', '446.580048')\n",
      "('Epoch:', '0157', 'Avg. cost =', '498.826843')\n",
      "('Epoch:', '0158', 'Avg. cost =', '415.352478')\n",
      "('Epoch:', '0159', 'Avg. cost =', '968.227966')\n",
      "('Epoch:', '0160', 'Avg. cost =', '541.497925')\n",
      "('Epoch:', '0161', 'Avg. cost =', '379.080902')\n",
      "('Epoch:', '0162', 'Avg. cost =', '611.492615')\n",
      "('Epoch:', '0163', 'Avg. cost =', '322.425812')\n",
      "('Epoch:', '0164', 'Avg. cost =', '508.270874')\n",
      "ERROR:tensorflow:Exception in QueueRunner: ../data/1train.tfrecords; No such file or directory\n",
      "\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](TFRecordReaderV2, input_producer)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ichang-geon/.pyenv/versions/2.7.14/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/ichang-geon/.pyenv/versions/2.7.14/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/ichang-geon/.pyenv/versions/2.7.14/envs/flow/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 252, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/Users/ichang-geon/.pyenv/versions/2.7.14/envs/flow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1244, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/Users/ichang-geon/.pyenv/versions/2.7.14/envs/flow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "NotFoundError: ../data/1train.tfrecords; No such file or directory\n",
      "\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](TFRecordReaderV2, input_producer)]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0165', 'Avg. cost =', '824.946045')\n",
      "('Epoch:', '0166', 'Avg. cost =', '718.452026')\n",
      "('Epoch:', '0167', 'Avg. cost =', '748.299133')\n"
     ]
    }
   ],
   "source": [
    "steps = 200\n",
    "\n",
    "for epoch in range(steps):    \n",
    "  total_cost = 0\n",
    "  _, cost_val = sess.run([total_loss, loss],feed_dict={})\n",
    "  total_cost += cost_val\n",
    "\n",
    "  print('Epoch:', '%04d' % (epoch + 1),\n",
    "        'Avg. cost =', '{:f}'.format(total_cost))\n",
    "print(\"최적화 완료\") \n",
    "saver.save(sess, \"./model_save/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
